{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from pm4py.objects.log.importer.xes import importer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as replay_fitness\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.algo.evaluation.generalization import algorithm as generalization_evaluator\n",
    "from pm4py.algo.evaluation.simplicity import algorithm as simplicity_evaluator\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading And Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and checking if the data is ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the event log CSV file\n",
    "csv_file_path = 'event_log.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert 'start_time' column to datetime if it's not already\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "\n",
    "# Find events where start_time equals end_time\n",
    "events_same_start_end = df[df['start_time'] == df['completion_time']]\n",
    "\n",
    "# Get list of event names where start and end times are the same\n",
    "event_names_same_start_end = events_same_start_end['event_label'].unique().tolist()\n",
    "\n",
    "# Display or further process event names where start and end times are the same\n",
    "print(\"Event names where start and end times are the same:\")\n",
    "print(event_names_same_start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the original CSV file\n",
    "df = pd.read_csv('event_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null cells in the entire DataFrame\n",
    "null_cells = df.isnull()\n",
    "print(True in null_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepering the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two dataframes where one will be more accurate (we will join the resource column to the events column) and the second will be more general (remove the resource column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first general dataframe : only removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general = df\n",
    "df_general = df_general.drop(columns=['resource', 'task_id', 'diagnosis', 'completion_time'])\n",
    "df_general.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the second more accurate dataframe : where we have a non None value we will merge it to the event_label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to modify the dataframe in place\n",
    "def transform_event_label_and_resource(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['resource'] != 'None':\n",
    "            # Change the event_label to the resource value\n",
    "            df.at[index, 'event_label'] = row['resource']\n",
    "            # Change the resource to 'None'\n",
    "            df.at[index, 'resource'] = 'None'\n",
    "    return df\n",
    "\n",
    "# Apply the transformation\n",
    "df_accurate = transform_event_label_and_resource(df)\n",
    "\n",
    "# Display the transformed dataframe\n",
    "df_accurate.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the resource column\n",
    "df_accurate = df_accurate.drop(columns=['resource', 'task_id', 'diagnosis', 'completion_time'])\n",
    "df_accurate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting to data to have a better look on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting the general dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_general = df_general.sort_values(['case_id', 'start_time'], ascending=[True, True])\n",
    "sorted_df_general.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting the more accurate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_accurate = df_accurate.sort_values(['case_id', 'start_time'], ascending=[True, True])\n",
    "sorted_df_accurate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data from CSV to XES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting both dataframes to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conveerting the accurate dataframe\n",
    "sorted_df_accurate.to_csv('accurate_event_log.csv', index=False)\n",
    "\n",
    "# conveerting the general dataframe\n",
    "sorted_df_general.to_csv('general_event_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from CSV format to XES format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe for conversion to XES\n",
    "sorted_df_general.rename(columns={'case_id': 'case:concept:name', 'event_label': 'concept:name', 'start_time': 'time:timestamp'}, inplace=True)\n",
    "sorted_df_general['time:timestamp'] = pd.to_datetime(sorted_df_general['time:timestamp'])\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "event_log = pm4py.format_dataframe(sorted_df_general, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "xes_event_log = pm4py.convert_to_event_log(event_log)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(xes_event_log, 'general_event_log.xes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe for conversion to XES\n",
    "sorted_df_accurate.rename(columns={'case_id': 'case:concept:name', 'event_label': 'concept:name', 'start_time': 'time:timestamp'}, inplace=True)\n",
    "sorted_df_accurate['time:timestamp'] = pd.to_datetime(sorted_df_accurate['time:timestamp'])\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "event_log = pm4py.format_dataframe(sorted_df_accurate, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "xes_event_log = pm4py.convert_to_event_log(event_log)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(xes_event_log, 'accurate_event_log.xes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Organizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We wanna know first what the activities we start and end with at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = importer.apply('general_event_log.xes')\n",
    "\n",
    "log_start = pm4py.get_start_activities(log)\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(list(log_start.items()), columns=['Activity', 'Count'])\n",
    "\n",
    "# Specify the file path for CSV\n",
    "csv_file_path = 'general_log_start_activities.csv'\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = importer.apply('general_event_log.xes')\n",
    "\n",
    "# Get end activities\n",
    "log_end = pm4py.get_end_activities(log)\n",
    "# Convert dictionary to DataFrame\n",
    "end_df = pd.DataFrame(list(log_end.items()), columns=['Activity', 'Count'])\n",
    "\n",
    "# Specify the file path for end activities CSV\n",
    "csv_file_path_end = 'general_log_end_activities.csv'\n",
    "# Export end activities to CSV\n",
    "end_df.to_csv(csv_file_path_end, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = importer.apply('accurate_event_log.xes')\n",
    "\n",
    "log_start = pm4py.get_start_activities(log)\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(list(log_start.items()), columns=['Activity', 'Count'])\n",
    "\n",
    "# Specify the file path for CSV\n",
    "csv_file_path = 'accurate_log_start_activities.csv'\n",
    "\n",
    "# Export to CSV\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = importer.apply('accurate_event_log.xes')\n",
    "\n",
    "# Get end activities\n",
    "log_end = pm4py.get_end_activities(log)\n",
    "# Convert dictionary to DataFrame\n",
    "end_df = pd.DataFrame(list(log_end.items()), columns=['Activity', 'Count'])\n",
    "\n",
    "# Specify the file path for end activities CSV\n",
    "csv_file_path_end = 'accurate_log_end_activities.csv'\n",
    "# Export end activities to CSV\n",
    "end_df.to_csv(csv_file_path_end, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We now wanna give number to each event and to get information about the processes that we can see in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping event labels to numbers\n",
    "event_label_to_number = {}\n",
    "current_number = 1  # Start with number 1\n",
    "\n",
    "for event_label in sorted_df_general['concept:name'].unique():\n",
    "    event_label_to_number[event_label] = current_number\n",
    "    current_number += 1\n",
    "\n",
    "# Create a new column 'number' based on event_label\n",
    "sorted_df_general['number'] = sorted_df_general['concept:name'].map(event_label_to_number)\n",
    "\n",
    "# Group by case_id and concatenate numbers into traces with spaces\n",
    "traces = sorted_df_general.groupby('case:concept:name')['number'].apply(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "\n",
    "# Count occurrences of each trace\n",
    "trace_counts = traces['number'].value_counts().reset_index()\n",
    "trace_counts.columns = ['trace', 'count']\n",
    "\n",
    "# Specify the file path for CSVs\n",
    "csv_file_path_trace_counts = 'general_trace_counts.csv'\n",
    "csv_file_path_case_traces = 'general_case_traces.csv'\n",
    "csv_file_path_general_meanings = 'general_meanings.csv'\n",
    "\n",
    "# Export trace counts to CSV\n",
    "trace_counts.to_csv(csv_file_path_trace_counts, index=False)\n",
    "\n",
    "# Export case_id and trace to CSV\n",
    "traces.columns = ['case_id', 'trace']\n",
    "traces.to_csv(csv_file_path_case_traces, index=False)\n",
    "\n",
    "# Create DataFrame for event meanings\n",
    "event_meanings = pd.DataFrame(list(event_label_to_number.items()), columns=['event', 'number'])\n",
    "event_meanings = event_meanings[['number', 'event']]  # Reorder columns\n",
    "\n",
    "# Export event meanings to CSV\n",
    "event_meanings.to_csv(csv_file_path_general_meanings, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping event labels to numbers\n",
    "event_label_to_number = {}\n",
    "current_number = 1  # Start with number 1\n",
    "\n",
    "for event_label in sorted_df_accurate['concept:name'].unique():\n",
    "    event_label_to_number[event_label] = current_number\n",
    "    current_number += 1\n",
    "\n",
    "# Create a new column 'number' based on event_label\n",
    "sorted_df_accurate['number'] = sorted_df_accurate['concept:name'].map(event_label_to_number)\n",
    "\n",
    "# Group by case_id and concatenate numbers into traces with spaces\n",
    "traces = sorted_df_accurate.groupby('case:concept:name')['number'].apply(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "\n",
    "# Count occurrences of each trace\n",
    "trace_counts = traces['number'].value_counts().reset_index()\n",
    "trace_counts.columns = ['trace', 'count']\n",
    "\n",
    "# Specify the file path for CSVs\n",
    "csv_file_path_trace_counts = 'accurate_trace_counts.csv'\n",
    "csv_file_path_case_traces = 'accurate_case_traces.csv'\n",
    "csv_file_path_accurate_meanings = 'accurate_meanings.csv'\n",
    "\n",
    "# Export trace counts to CSV\n",
    "trace_counts.to_csv(csv_file_path_trace_counts, index=False)\n",
    "\n",
    "# Export case_id and trace to CSV\n",
    "traces.columns = ['case_id', 'trace']\n",
    "traces.to_csv(csv_file_path_case_traces, index=False)\n",
    "\n",
    "# Create DataFrame for event meanings\n",
    "event_meanings = pd.DataFrame(list(event_label_to_number.items()), columns=['event', 'number'])\n",
    "event_meanings = event_meanings[['number', 'event']]  # Reorder columns\n",
    "\n",
    "# Export event meanings to CSV\n",
    "event_meanings.to_csv(csv_file_path_accurate_meanings, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms And Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training and testing sets\n",
    "general_train, general_test = train_test_split(sorted_df_general, test_size=0.4, random_state=42)\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "general_event_log_train = pm4py.format_dataframe(general_train, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "general_xes_event_log_train = pm4py.convert_to_event_log(general_event_log_train)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(general_xes_event_log_train, 'general_event_log_train.xes')\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "general_event_log_test = pm4py.format_dataframe(general_test, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "general_xes_event_log_test = pm4py.convert_to_event_log(general_event_log_test)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(general_xes_event_log_test, 'general_event_log_test.xes')\n",
    "\n",
    "# Save the training and testing sets to separate CSV files\n",
    "general_train.to_csv('general_train_event_log.csv', index=False)\n",
    "general_test.to_csv('general_test_event_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training and testing sets\n",
    "accurate_train, accurate_test = train_test_split(sorted_df_accurate, test_size=0.4, random_state=42)\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "accurate_event_log_train = pm4py.format_dataframe(accurate_train, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "accurate_xes_event_log_train = pm4py.convert_to_event_log(accurate_event_log_train)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(accurate_xes_event_log_train, 'accurate_event_log_train.xes')\n",
    "\n",
    "# Convert the dataframe to an XES event log\n",
    "accurate_event_log_test = pm4py.format_dataframe(accurate_test, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "accurate_xes_event_log_test = pm4py.convert_to_event_log(accurate_event_log_test)\n",
    "\n",
    "# Save the XES event log to a file\n",
    "pm4py.write_xes(accurate_xes_event_log_test, 'accurate_event_log_test.xes')\n",
    "\n",
    "# Save the training and testing sets to separate CSV files\n",
    "accurate_train.to_csv('accurate_train_event_log.csv', index=False)\n",
    "accurate_test.to_csv('accurate_test_event_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alpha algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the event log\n",
    "general_alpha_xes_event_log_train = pm4py.read_xes('general_event_log_train.xes')\n",
    "\n",
    "# Apply the Alpha Miner algorithm to discover a Petri net\n",
    "general_alpha_net, general_alpha_initial_marking, general_alpha_final_marking = alpha_miner.apply(general_alpha_xes_event_log_train)\n",
    "\n",
    "# Save the Petri net to a PNML file\n",
    "pm4py.write_pnml(general_alpha_net, general_alpha_initial_marking, general_alpha_final_marking, 'general_alpha_mined_petri_net.pnml')\n",
    "\n",
    "# Visualize the Petri net\n",
    "pm4py.view_petri_net(general_alpha_net, general_alpha_initial_marking, general_alpha_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the event log\n",
    "accurate_alpha_xes_event_log_train = pm4py.read_xes('accurate_event_log_train.xes')\n",
    "\n",
    "# Apply the Alpha Miner algorithm to discover a Petri net\n",
    "accurate_alpha_net, accurate_alpha_initial_marking, accurate_alpha_final_marking = alpha_miner.apply(accurate_alpha_xes_event_log_train)\n",
    "\n",
    "# Save the Petri net to a PNML file\n",
    "pm4py.write_pnml(accurate_alpha_net, accurate_alpha_initial_marking, accurate_alpha_final_marking, 'accurate_alpha_mined_petri_net.pnml')\n",
    "\n",
    "# Visualize the Petri net\n",
    "pm4py.view_petri_net(accurate_alpha_net, accurate_alpha_initial_marking, accurate_alpha_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inductive algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_log_inductive = pm4py.read_xes('general_event_log_train.xes')\n",
    "general_inductive_net, general_inductive_initial_marking, general_inductive_final_marking = pm4py.discover_petri_net_inductive(general_log_inductive)\n",
    "pm4py.write_pnml(general_inductive_net, general_inductive_initial_marking, general_inductive_final_marking, 'general_inductive_mined_petri_net.pnml')\n",
    "pm4py.view_petri_net(general_inductive_net, general_inductive_initial_marking, general_inductive_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_log_inductive = pm4py.read_xes('accurate_event_log_train.xes')\n",
    "accurate_inductive_net, accurate_inductive_initial_marking, accurate_inductive_final_marking = pm4py.discover_petri_net_inductive(accurate_log_inductive)\n",
    "pm4py.write_pnml(accurate_inductive_net, accurate_inductive_initial_marking, accurate_inductive_final_marking, 'accurate_inductive_mined_petri_net.pnml')\n",
    "pm4py.view_petri_net(accurate_inductive_net, accurate_inductive_initial_marking, accurate_inductive_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heuristic algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the event log\n",
    "general_heuristic_xes_event_log_train = pm4py.read_xes('general_event_log_train.xes')\n",
    "\n",
    "# Apply the Heuristic Miner algorithm to discover a Petri net\n",
    "general_heuristic_net, general_heuristic_initial_marking, general_heuristic_final_marking = pm4py.discover_petri_net_heuristics(general_heuristic_xes_event_log_train)\n",
    "\n",
    "# Save the Petri net to a PNML file\n",
    "pm4py.write_pnml(general_heuristic_net, general_heuristic_initial_marking, general_heuristic_final_marking, 'general_heuristic_mined_petri_net.pnml')\n",
    "pm4py.view_petri_net(general_heuristic_net, general_heuristic_initial_marking, general_heuristic_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the event log\n",
    "accurate_heuristic_xes_event_log_train = pm4py.read_xes('accurate_event_log_train.xes')\n",
    "\n",
    "# Apply the Heuristic Miner algorithm to discover a Petri net\n",
    "accurate_heuristic_net, accurate_heuristic_initial_marking, accurate_heuristic_final_marking = pm4py.discover_petri_net_heuristics(accurate_heuristic_xes_event_log_train)\n",
    "\n",
    "# Save the Petri net to a PNML file\n",
    "pm4py.write_pnml(accurate_heuristic_net, accurate_heuristic_initial_marking, accurate_heuristic_final_marking, 'accurate_heuristic_mined_petri_net.pnml')\n",
    "pm4py.view_petri_net(accurate_heuristic_net, accurate_heuristic_initial_marking, accurate_heuristic_final_marking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformence Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables for the model accuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate performance using the test log\n",
    "def evaluate_performance(log, net, initial_marking, final_marking):\n",
    "    # Fitness\n",
    "    fitness_value = replay_fitness.apply(log, net, initial_marking, final_marking)['averageFitness']\n",
    "    \n",
    "    # Precision\n",
    "    precision_value = precision_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "    \n",
    "    # Generalization\n",
    "    generalization_value = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "    \n",
    "    # Simplicity\n",
    "    simplicity_value = simplicity_evaluator.apply(net)\n",
    "    \n",
    "    return {\n",
    "        \"fitness\": fitness_value,\n",
    "        \"precision\": precision_value,\n",
    "        \"generalization\": generalization_value,\n",
    "        \"simplicity\": simplicity_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for alpha algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_alpha_performance = evaluate_performance(general_xes_event_log_test, general_alpha_net, general_alpha_initial_marking, general_alpha_final_marking)\n",
    "print(general_alpha_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_alpha_performance = evaluate_performance(accurate_xes_event_log_test, accurate_alpha_net, accurate_alpha_initial_marking, accurate_alpha_final_marking)\n",
    "print(accurate_alpha_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for inductive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_inductive_performance = evaluate_performance(general_xes_event_log_test, general_inductive_net, general_inductive_initial_marking, general_inductive_final_marking)\n",
    "print(general_inductive_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_inductive_performance = evaluate_performance(accurate_xes_event_log_test, accurate_inductive_net, accurate_inductive_initial_marking, accurate_inductive_final_marking)\n",
    "print(accurate_inductive_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for heuristic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_heuristic_performance = evaluate_performance(general_xes_event_log_test, general_heuristic_net, general_heuristic_initial_marking, general_heuristic_final_marking)\n",
    "print(general_heuristic_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate_heuristic_performance = evaluate_performance(accurate_xes_event_log_test, accurate_heuristic_net, accurate_heuristic_initial_marking, accurate_heuristic_final_marking)\n",
    "print(accurate_heuristic_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replay method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for alpha algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(general_xes_event_log_test, general_alpha_net, general_alpha_initial_marking, general_alpha_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(accurate_xes_event_log_test, accurate_alpha_net, accurate_alpha_initial_marking, accurate_alpha_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for inductive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(general_xes_event_log_test, general_inductive_net, general_inductive_initial_marking, general_inductive_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(accurate_xes_event_log_test, accurate_inductive_net, accurate_inductive_initial_marking, accurate_inductive_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for heuristic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the general dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(general_xes_event_log_test, general_heuristic_net, general_heuristic_initial_marking, general_heuristic_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the accurate dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform token-based replay conformance checking\n",
    "replay_result = token_replay.apply(accurate_xes_event_log_test, accurate_heuristic_net, accurate_heuristic_initial_marking, accurate_heuristic_final_marking)\n",
    "\n",
    "# Convert replay results to a DataFrame manually\n",
    "records = []\n",
    "for case in replay_result:\n",
    "    missing_tokens = case['missing_tokens']\n",
    "    remaining_tokens = case['remaining_tokens']\n",
    "    produced_tokens = case['produced_tokens']\n",
    "    consumed_tokens = case['consumed_tokens']\n",
    "    fit_traces = case['trace_is_fit']\n",
    "    \n",
    "    records.append({\n",
    "        'missing_tokens': missing_tokens,\n",
    "        'remaining_tokens': remaining_tokens,\n",
    "        'produced_tokens': produced_tokens,\n",
    "        'consumed_tokens': consumed_tokens,\n",
    "        'fit_traces': fit_traces\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Calculate the total missing, extra, produced, and consumed tokens\n",
    "total_missing_tokens = df['missing_tokens'].sum()\n",
    "total_extra_tokens = df['remaining_tokens'].sum()\n",
    "total_produced_tokens = df['produced_tokens'].sum()\n",
    "total_consumed_tokens = df['consumed_tokens'].sum()\n",
    "\n",
    "# Print the summary\n",
    "print(f\"Total Missing Tokens: {total_missing_tokens}\")\n",
    "print(f\"Total Remaining Tokens: {total_extra_tokens}\")\n",
    "print(f\"Total Produced Tokens: {total_produced_tokens}\")\n",
    "print(f\"Total Consumed Tokens: {total_consumed_tokens}\")\n",
    "\n",
    "fitness = 0.5 * (1 - total_missing_tokens / total_produced_tokens) + 0.5 * (1 - total_extra_tokens / total_consumed_tokens)\n",
    "print(f\"Fitness: {fitness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the trace counts from CSV\n",
    "trace_counts = pd.read_csv('trace_counts.csv')\n",
    "\n",
    "def remove_consecutive_duplicates(trace):\n",
    "    numbers = trace.split()\n",
    "    result = [numbers[0]]\n",
    "    for num in numbers[1:]:\n",
    "        if num != result[-1]:\n",
    "            result.append(num)\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Apply the function to remove consecutive duplicates\n",
    "trace_counts['trace'] = trace_counts['trace'].apply(remove_consecutive_duplicates)\n",
    "\n",
    "# Group by the trace and sum the counts\n",
    "deduplicated_trace_counts = trace_counts.groupby('trace')['count'].sum().reset_index()\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "deduplicated_trace_counts = deduplicated_trace_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Export the deduplicated and sorted trace counts to CSV\n",
    "csv_file_path_deduplicated = 'trace_counts.csv'\n",
    "deduplicated_trace_counts.to_csv(csv_file_path_deduplicated, index=False)\n",
    "\n",
    "# Select the top 7 most frequent traces\n",
    "top_traces = deduplicated_trace_counts.head(10)\n",
    "\n",
    "# Create a bar chart of the top 7 trace counts\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(top_traces['trace'], top_traces['count'], color='skyblue')\n",
    "plt.xlabel('Trace')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Most Frequent Trace Counts')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "\n",
    "# Save the bar chart to a file\n",
    "bar_chart_path = 'top_trace_counts_bar_chart.png'\n",
    "plt.savefig(bar_chart_path)\n",
    "\n",
    "# Display the bar chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of events per case\n",
    "case_event_counts = sorted_df['case:concept:name'].value_counts()\n",
    "\n",
    "# Plot the distribution of case lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(case_event_counts, kde=True, color='purple')\n",
    "plt.title('Distribution of Events per Case')\n",
    "plt.xlabel('Number of Events per Case')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Display the case event counts\n",
    "print(case_event_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few cases to visualize\n",
    "sample_cases = sorted_df[sorted_df['case:concept:name'].isin(sorted_df['case:concept:name'].unique()[:5])]\n",
    "\n",
    "# Plot the event sequences for the selected cases\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(x='time:timestamp', y='concept:name', hue='case:concept:name', data=sample_cases, marker='o')\n",
    "plt.title('Event Sequences for Sample Cases')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Event Name')\n",
    "plt.legend(title='Case ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for sequence mining\n",
    "cases = sorted_df.groupby('case:concept:name')['concept:name'].apply(list).values\n",
    "\n",
    "# Encode the data\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(cases).transform(cases)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Display the results\n",
    "print(frequent_itemsets)\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
